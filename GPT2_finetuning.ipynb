{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "collapsed_sections": [
        "3f9ee8BwLHPT",
        "cncP61fILYJM",
        "ilLUf-4WLa4l",
        "Ee1zHG09yJsO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b25b1972e74a473ca3f8ce6a6417f778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad9658955bb543878d95a2a149770222",
              "IPY_MODEL_23b977b6f42942869417ee080169dd89",
              "IPY_MODEL_8f0ae11370fe484da2cd600c4e509d41"
            ],
            "layout": "IPY_MODEL_b3b6811c53594b70bfe49b1f91190ff8"
          }
        },
        "ad9658955bb543878d95a2a149770222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f135c345b6934963b7bc5d2e5a8be83e",
            "placeholder": "​",
            "style": "IPY_MODEL_bc5c6075f2e443bb81f7b7d72f197315",
            "value": "100%"
          }
        },
        "23b977b6f42942869417ee080169dd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3014e607ff4c439a919dedca8708ee6a",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ae88bc8e95e492da94f460aadcc26c3",
            "value": 50
          }
        },
        "8f0ae11370fe484da2cd600c4e509d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1d425f14c484aea95b435308e15b4de",
            "placeholder": "​",
            "style": "IPY_MODEL_0c124c98549c4facb890a98766badc90",
            "value": " 50/50 [11:59&lt;00:00, 19.05s/it]"
          }
        },
        "b3b6811c53594b70bfe49b1f91190ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f135c345b6934963b7bc5d2e5a8be83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc5c6075f2e443bb81f7b7d72f197315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3014e607ff4c439a919dedca8708ee6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae88bc8e95e492da94f460aadcc26c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1d425f14c484aea95b435308e15b4de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c124c98549c4facb890a98766badc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7b8ed9210484eaea7768523e0420bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c2e2df20ec046db92baca547b757a51",
              "IPY_MODEL_399329a5261140059f7427d727a497b5",
              "IPY_MODEL_2775d645803e4e2c80c9d345f1e750ed"
            ],
            "layout": "IPY_MODEL_5ead242ad3fb4eb7b58f9d22994f01b6"
          }
        },
        "9c2e2df20ec046db92baca547b757a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c9e56e5b5224edd9159d0f5c3a9bb8e",
            "placeholder": "​",
            "style": "IPY_MODEL_49f21850f0504aa9a78b8c4b5edf2851",
            "value": "100%"
          }
        },
        "399329a5261140059f7427d727a497b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6205d276de44f5f8b3858147c43ed83",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_620c50fc69e54037a5692a13cecb635b",
            "value": 50
          }
        },
        "2775d645803e4e2c80c9d345f1e750ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d43c7cf683e4239b89da09485ba945a",
            "placeholder": "​",
            "style": "IPY_MODEL_9d41ebb2d1db48c89325feec2ed0ea72",
            "value": " 50/50 [24:55&lt;00:00, 41.00s/it]"
          }
        },
        "5ead242ad3fb4eb7b58f9d22994f01b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c9e56e5b5224edd9159d0f5c3a9bb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f21850f0504aa9a78b8c4b5edf2851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6205d276de44f5f8b3858147c43ed83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "620c50fc69e54037a5692a13cecb635b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d43c7cf683e4239b89da09485ba945a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d41ebb2d1db48c89325feec2ed0ea72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines -q\n",
        "!pip install -q gpt-2-simple\n",
        "!pip install evaluate -q\n",
        "!pip install rouge_score -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUPA_dgsOn-4",
        "outputId": "dad03698-3c45-4204-8f04-531b323f6a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_05IKn4O-WV",
        "outputId": "8894e114-7d01-4ea3-de7e-e2fc1519d69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "import pandas as pd \n",
        "import re \n",
        "from tqdm.auto import tqdm \n",
        "import jsonlines\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare data"
      ],
      "metadata": {
        "id": "DSWMkUMVLFWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train"
      ],
      "metadata": {
        "id": "3f9ee8BwLHPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('./drive/My Drive/chatgpt_results_correct.jsonl', 'r') as jsonl_f:\n",
        "  lst = [obj for obj in jsonl_f]\n",
        "sum_parsed_train = \"<|endoftext|>\".join(\"{0}|{1}\".format('[INPUT]'+j['input'], '[OUTPUT]'+j['output']) for j in lst[:50])\n"
      ],
      "metadata": {
        "id": "wUdMzpeJppvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/My Drive/inp_chatgpt.txt\"\n",
        "Path(file_name).write_text(sum_parsed_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYgotrFQpqe9",
        "outputId": "66843320-cf93-42d6-c92c-16dcc3a01d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1596240"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "fLepOFpDLI1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('./drive/My Drive/chat_gpt_results_few_final.jsonlines', 'r') as jsonl_f:\n",
        "  lst = [obj for obj in jsonl_f]"
      ],
      "metadata": {
        "id": "Ngci85HjLLoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_json = lst[:50]"
      ],
      "metadata": {
        "id": "8FouZyPJLPrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train GPT2"
      ],
      "metadata": {
        "id": "NfO9tCl3Kks-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 124M"
      ],
      "metadata": {
        "id": "cncP61fILYJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L1eblMJQd_X",
        "outputId": "639f162c-b4f1-4593-bb49-27b817758a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 512Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 2.71Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 926Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:15, 32.2Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 804Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.10Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 3.52Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run124',\n",
        "              print_every=50,\n",
        "              sample_every=500,\n",
        "              save_every=500\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7qtp7R3QZLl",
        "outputId": "8e25692f-dd23-4ab7-ca48-d61d4a84729c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 373599 tokens\n",
            "Training...\n",
            "[50 | 22.29] loss=2.15 avg=2.15\n",
            "[100 | 38.50] loss=1.97 avg=2.06\n",
            "[150 | 54.69] loss=2.04 avg=2.05\n",
            "[200 | 70.88] loss=1.59 avg=1.93\n",
            "[250 | 87.08] loss=1.42 avg=1.83\n",
            "[300 | 103.27] loss=1.29 avg=1.74\n",
            "[350 | 119.47] loss=1.38 avg=1.68\n",
            "[400 | 135.66] loss=1.00 avg=1.60\n",
            "[450 | 151.85] loss=0.71 avg=1.49\n",
            "[500 | 168.05] loss=0.86 avg=1.43\n",
            "Saving checkpoint/run124500/model-500\n",
            "======== SAMPLE 1 ========\n",
            " superior and faster than the HTC Siemens M710.\n",
            "3. The faster processor- and graphics-processing unit of the Nokia processor-unit approximately 8MB is than the 32MHz clocked of the Siemens MT8610 .\n",
            "4. Also, the wi-fi in my apartment is better than the nokia.\n",
            "5. But let me just put it this way: it's much nicer, much safer, much easier to use, in many ways, than traveling through Middle Eastern despots writhing in the heat.\n",
            "6. But to answer your question, mobile broadband in any form is a better idea than cable television or Netflix, because people can watch TV from your car or truck.\n",
            "7. And who wouldn't want a mobile-phone so much better than a TV, where as television, cable and beyond, can be a vast luxury.\n",
            "8. If you have a small business, say where a mobile phone is essential, the customer service at my reindeer farm is superior to a television set.\n",
            "9. The mobile site is run using what seems to be a secure server which is hardly pilfered information but rather converts plain text data into HTML as fastcgi is fastcgi adequate.\n",
            "10. Even in rural areas, with only a moderately mobile population, cabling capacity of about 2,000 people per square mile is a million times greater than the rural area cable operators.\n",
            "11. And, as I just said, fibre-optic cable is probably slower than fiber-optic cable used to be, but it's faster than copper.\n",
            "12. And for his money, Amazon could be a cheaper (and safer) way to distribute and consume content than Google Inc's mass-circulation Instant content.\n",
            "13. That leaves you with two options - pay tribute to George Washington and erect a Star of David or erect a digital image of George Washington that you can post on YouTube or any other medium you prefer.\n",
            "\n",
            "After the summary, list the arguments you used below the text. Put citations in brackets inside the text. Do not even mention arguments that are not relevant to amazon and google.|[OUTPUT]amazon and Google are two major competitors in the information and software industries. \n",
            "\n",
            "Amazon is often praised for being far superior to rival companies like Microsoft and Google [2][3][7]. It provides a greater variety of content and user experience with greater scalability [14][16][17]. Amazon's dominance in the e-commerce space can also be seen in the fact that Amazon is the preferred store of consumer electronics by Amazon's customers [4]. \n",
            "\n",
            "However, Amazon is still being beaten, or at least criticized, against significantly better quality and content than competitors Google Inc. and Facebook Inc [4]. Some also perceive Amazon as being less honest with its investors [10] and doing better job of PR than its big competitors [3]. \n",
            "\n",
            "There is also controversy surrounding the quality of digital media associated with each store. Some even argue that Amazon-like quality is the only thing that makes it better [6]. \n",
            "\n",
            "Ultimately, the choice between Amazon and Google depends on personal preferences, such as the quality of content, selection, and ease of use. \n",
            "\n",
            "Arguments used: 2, 3, 4, 6, 7, 10, 14, 16, 17, 19.<|endoftext|>[INPUT]Write a comparison of \"amazonian\" and \"google\". Summarize only relevant arguments from the list.\n",
            "\n",
            "1. \"Amazonian\" also has a more pleasant climate in America than its northern Canadian Canadian counterpart.\n",
            "2. If Amazon is successful, Kleiner Perkins says it's easier to grow an American company than it is an American company, and Facebook says it's harder to grow an American company than Facebook.\n",
            "3. Amazon set a world record for delivery within 5 days of receiving it, far faster than Google.\n",
            "4. Amazon was easier to rank than google.\n",
            "5. Amazon is a superior online store, far better organized and better made than Amazon.\n",
            "6. I personally think that Amazon's system of self-storerability and self-similarity (which means that different products may work on different people) is superior to ebay or bidders information.\n",
            "7. We've already tracked down almost 5,000 Amazonian (pronounced \"Better-Naw-na-SHAH-ko-)in-California -- that's more than the number of people who responded to our door in California last week).\n",
            "8. There is no better place for content owners than Amazon.\n",
            "9. They are, after all, the largest online retailer for film and TV series, including some far greater than the combined sales of Barnes & Noble and Amazon.\n",
            "10. It is from this source, or rather, that we derive some of the profits, that Amazon's prices are higher than those of most established retailers.\n",
            "11. This means that delivery people can expect to\n",
            "\n",
            "[550 | 196.89] loss=0.53 avg=1.34\n",
            "[600 | 213.09] loss=0.53 avg=1.27\n",
            "[650 | 229.30] loss=0.48 avg=1.20\n",
            "[700 | 245.51] loss=0.39 avg=1.14\n",
            "[750 | 261.72] loss=0.32 avg=1.08\n",
            "[800 | 277.93] loss=0.23 avg=1.03\n",
            "[850 | 294.14] loss=0.37 avg=0.98\n",
            "[900 | 310.34] loss=0.24 avg=0.94\n",
            "[950 | 326.54] loss=0.25 avg=0.90\n",
            "[1000 | 342.75] loss=0.21 avg=0.86\n",
            "Saving checkpoint/run124500/model-1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run124')"
      ],
      "metadata": {
        "id": "054kswD8RDX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 345M"
      ],
      "metadata": {
        "id": "ilLUf-4WLa4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2(model_name=\"345M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gi-iiRALuWL",
        "outputId": "6d886fd6-3f0a-4e81-f246-fd57bdf30714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 587Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 2.71Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 733Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:42, 33.4Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 643Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.06Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 3.50Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='345M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run345',\n",
        "              print_every=50,\n",
        "              sample_every=500,\n",
        "              save_every=500\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROpfII4yLuXq",
        "outputId": "b31cde35-a876-4a1d-b257-9d2514bbd315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For larger models, the recommended finetune() parameters are:\n",
            "\tuse_memory_saving_gradients = True\n",
            "\tonly_train_transformer_layers = True\n",
            "\taccumulate_gradients = 1\n",
            "\n",
            "Loading checkpoint models/345M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 373599 tokens\n",
            "Training...\n",
            "[50 | 53.88] loss=1.99 avg=1.99\n",
            "[100 | 92.70] loss=1.69 avg=1.84\n",
            "[150 | 131.55] loss=1.57 avg=1.75\n",
            "[200 | 170.40] loss=1.12 avg=1.59\n",
            "[250 | 209.23] loss=0.84 avg=1.44\n",
            "[300 | 248.05] loss=0.90 avg=1.35\n",
            "[350 | 286.90] loss=0.43 avg=1.21\n",
            "[400 | 325.74] loss=0.83 avg=1.16\n",
            "[450 | 364.59] loss=0.35 avg=1.07\n",
            "[500 | 403.40] loss=0.22 avg=0.98\n",
            "Saving checkpoint/run345500/model-500\n",
            "======== SAMPLE 1 ========\n",
            " of Perl as much as Python.\n",
            "11. However, python looks nicer and in many ways is actually simpler and for many tasks easier to pick up than Perl.\n",
            "12. I'm having a hard time understanding how Perl IS so much smarter than Python.\n",
            "13. Python integrates simpler than Perl and is better readable than Perl.\n",
            "14. A version of Python better than 1.7 would be nice, along with a better implementation of Unix socket.\n",
            "15. Python is \"faster\" than Perl.\n",
            "16. Perl was faster than PHP for many years, and now Python is fast.\n",
            "17. I'm not sure the exact reason for python to be so faster than Perl, but I would bet its because of Google's influence with Python.\n",
            "18. Perl is more of a \"sandwich sauce\" than a \"bread sauce\", and sweeteners are added endearing themselves.\n",
            "19. So it proves even more than Python is quicker than Perl, which is the fastest language out there right now.\n",
            "20. the fact is peper is considerably faster than perl.\n",
            "\n",
            "After the summary, list the arguments you used below the text. Put citations in brackets inside the text. Do not even mention arguments that are not relevant to Perl and Python.|[OUTPUT]Perl and Python are two popular programming languages used for various applications. \n",
            "\n",
            "Perl is considered to be a simpler language than Python [1][8], but it is also easier to write applications [7]. Some people argue that Perl is faster than Python [12][19] and uses of Perl are not as prominent as other languages like Java and Ruby [3]. However, others claim that Perl is simpler than Python [10] and easier to write applications [7]. Some users also suggest that Perl is better suited for blogging [11], while others praise Python's performance [18]. \n",
            "\n",
            "Overall, the choice between Perl and Python depends on personal preferences. While Perl is simpler for some applications [14][19], it can also be more suited for certain tasks, like blogging [18]. Additionally, some users argue that PHP is faster than Perl in most benchmarks [5][8], while others claim that Python is faster than Perl in one [9]. \n",
            "\n",
            "Arguments used: 1, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 18, 19.<|endoftext|>[INPUT]Write a comparison of \"cement\" and \"metal\". Summarize only relevant arguments from the list.\n",
            "\n",
            "1. EccoBoard™ is lighter and easier to handle than regular cement board.\n",
            "2. In addition, calcium phosphate was found to have a faster breaking point than cement per 100 grams.\n",
            "3. \"Metal is harder than cement,\" he said.\n",
            "4. Here's why it's way cooler than metal....Cement is cheap and makes things brittle.\n",
            "5. It's the sort of thing that would stick to metal much better than cement.\n",
            "6. In a nutshell,, it sounds much better than \"metal is harder than concrete\".\n",
            "7. - Poured cement board is not less waterproof than glass, though it was a little lighter in color.\n",
            "8. For example, wood can corrode - and worse, cement is a poor conductor of heat.\n",
            "9. \"After five minutes in the sun, cement hardens and is less durable than slate or slate,\" said Bond.\n",
            "10. Yes, cement is a worse conductor than metal or plastic.\n",
            "11. Concrete is a better conductor than metal and, with time, superior to steel.\n",
            "12. Concrete is superior to metal, especially near metal components.\n",
            "13. It is made of concrete with few metals, in this photo by Shore Guardian showcasing their exclusive \"Metal Roofing Systems\" (Rooms can't get any better than metal!)\n",
            "14. Concrete is superior to metal and will resist the abuse of time, cold, and moisture better than wood.\n",
            "15. The metal brackets are much easier to install than galvanized metal bolts.\n",
            "16. It's made of concrete which, while lighter than metal, is much harder than metal.\n",
            "17. Yes, concrete is superior to metal for rowing.\n",
            "18. This is darker than a typical coffee table cement one, but Temptation's metal construction avoids any concerns of metal fatigue.\n",
            "19. \"Rubber mats, wood chips, or sand can absorb the impact much better than cement or asphalt.\n",
            "20. What you want is something that is durable, long-lasting, and non-porous.\n",
            "\n",
            "After the summary, list the arguments you used below the text. Put citations in brackets inside the text. Do not even mention arguments that are not relevant to cement and metal.|[OUTPUT]Cement is one of the most widely used materials in construction, and it has various applications in various industries. \n",
            "\n",
            "According to various arguments\n",
            "\n",
            "[550 | 467.30] loss=0.26 avg=0.91\n",
            "[600 | 506.12] loss=0.22 avg=0.85\n",
            "[650 | 544.94] loss=0.16 avg=0.79\n",
            "[700 | 583.75] loss=0.13 avg=0.74\n",
            "[750 | 622.56] loss=0.13 avg=0.70\n",
            "[800 | 661.39] loss=0.16 avg=0.66\n",
            "[850 | 700.25] loss=0.10 avg=0.63\n",
            "[900 | 739.10] loss=0.09 avg=0.59\n",
            "[950 | 777.98] loss=0.08 avg=0.56\n",
            "[1000 | 816.83] loss=0.07 avg=0.54\n",
            "Saving checkpoint/run345500/model-1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run345')"
      ],
      "metadata": {
        "id": "qrwkWT-rLuZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model"
      ],
      "metadata": {
        "id": "eF1hiNPoLyAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 124M"
      ],
      "metadata": {
        "id": "Ee1zHG09yJsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generating"
      ],
      "metadata": {
        "id": "6xbmcSGGXl-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run124')"
      ],
      "metadata": {
        "id": "W92douB5RJZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run124')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-h0AsCjRLDh",
        "outputId": "0577f075-5b05-46f2-d3de-df8378b19573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run124500/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_json = []\n",
        "for summ in tqdm(test_json):\n",
        "  obj1 = summ['obj1']\n",
        "  obj2 = summ['obj2']\n",
        "  prefix = summ['input']\n",
        "  output_chatgpt = summ['outputs'][0]\n",
        "  output_gpt2 = gpt2.generate(sess,\n",
        "              run_name='run124',\n",
        "              return_as_list=True,\n",
        "              include_prefix=False,\n",
        "              prefix=prefix,\n",
        "              length=1000,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              truncate='<|endoftext|>'\n",
        "              )[0]\n",
        "\n",
        "  evaluate_json.append({'obj1': obj1, 'obj2': obj2, 'input': prefix, 'gpt2_output': output_gpt2, 'gold_output': output_chatgpt})"
      ],
      "metadata": {
        "id": "5ZjzDzK8sfVi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b25b1972e74a473ca3f8ce6a6417f778",
            "ad9658955bb543878d95a2a149770222",
            "23b977b6f42942869417ee080169dd89",
            "8f0ae11370fe484da2cd600c4e509d41",
            "b3b6811c53594b70bfe49b1f91190ff8",
            "f135c345b6934963b7bc5d2e5a8be83e",
            "bc5c6075f2e443bb81f7b7d72f197315",
            "3014e607ff4c439a919dedca8708ee6a",
            "2ae88bc8e95e492da94f460aadcc26c3",
            "e1d425f14c484aea95b435308e15b4de",
            "0c124c98549c4facb890a98766badc90"
          ]
        },
        "outputId": "93b02532-67c6-45d7-dd5e-97a74da66d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b25b1972e74a473ca3f8ce6a6417f778"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ev in evaluate_json:\n",
        "  try:\n",
        "    ev['gpt2_output'] = ev['gpt2_output'].split('[OUTPUT]')[1]\n",
        "  except:\n",
        "    print(ev['gpt2_output'])\n",
        "    ev['gpt2_output'] = ''\n"
      ],
      "metadata": {
        "id": "HFi00lM5yliM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('./drive/My Drive/gpt2_results_for_eval_124m.jsonl', mode='w') as writer:\n",
        "    writer.write_all(evaluate_json) "
      ],
      "metadata": {
        "id": "ByqycB2Cuv3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluating ROUGE, BLEU"
      ],
      "metadata": {
        "id": "LZD-M4xUW9Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('./drive/My Drive/gpt2_results_for_eval_124m.jsonl', 'r') as jsonl_f:\n",
        "  evaluate_json = [obj for obj in jsonl_f]"
      ],
      "metadata": {
        "id": "rxJOoGTR4CR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [j['gpt2_output'] for j in evaluate_json]\n",
        "references = [j['gold_output'] for j in evaluate_json]"
      ],
      "metadata": {
        "id": "cVSm2rLr4IP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "results = rouge.compute(predictions=predictions,\n",
        "                        references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o-mM02ZGyNS",
        "outputId": "92dd8fe7-f2b7-46d4-ba2a-c87e2b3e11f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 0.4949008432837968, 'rouge2': 0.20234875959195042, 'rougeL': 0.3182645740701917, 'rougeLsum': 0.42970017187727516}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [j['gpt2_output'] for j in evaluate_json]\n",
        "references = [[j['gold_output']] for j in evaluate_json]"
      ],
      "metadata": {
        "id": "k-gbVvvMG0tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "results = bleu.compute(predictions=predictions, references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URMzPuff4jhf",
        "outputId": "187a7ecb-9785-4f52-8d96-58faf2980b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 0.2546405024278543, 'precisions': [0.5681074565179955, 0.3180285343709468, 0.1952066689822855, 0.11921165082410395], 'brevity_penalty': 1.0, 'length_ratio': 1.0286979627989372, 'translation_length': 11614, 'reference_length': 11290}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 345M\n"
      ],
      "metadata": {
        "id": "jLIh0wc5yLm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generating"
      ],
      "metadata": {
        "id": "5h-iCKgTXow2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run345')"
      ],
      "metadata": {
        "id": "rzNVdLloyPYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run345')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY8B1wWzyPbr",
        "outputId": "7b51cd3c-69ff-4da7-ed6d-6d7e352dcae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run345500/model-1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_json = []\n",
        "for summ in tqdm(test_json):\n",
        "  obj1 = summ['obj1']\n",
        "  obj2 = summ['obj2']\n",
        "  prefix = summ['input']\n",
        "  output_chatgpt = summ['outputs'][0]\n",
        "  output_gpt2 = gpt2.generate(sess,\n",
        "              run_name='run345',\n",
        "              return_as_list=True,\n",
        "              include_prefix=False,\n",
        "              prefix=prefix,\n",
        "              length=1000,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              truncate='<|endoftext|>'\n",
        "              )[0]\n",
        "\n",
        "  evaluate_json.append({'obj1': obj1, 'obj2': obj2, 'input': prefix, 'gpt2_output': output_gpt2, 'gold_output': output_chatgpt})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e7b8ed9210484eaea7768523e0420bfc",
            "9c2e2df20ec046db92baca547b757a51",
            "399329a5261140059f7427d727a497b5",
            "2775d645803e4e2c80c9d345f1e750ed",
            "5ead242ad3fb4eb7b58f9d22994f01b6",
            "8c9e56e5b5224edd9159d0f5c3a9bb8e",
            "49f21850f0504aa9a78b8c4b5edf2851",
            "f6205d276de44f5f8b3858147c43ed83",
            "620c50fc69e54037a5692a13cecb635b",
            "4d43c7cf683e4239b89da09485ba945a",
            "9d41ebb2d1db48c89325feec2ed0ea72"
          ]
        },
        "id": "Oz7-zEVFyPtk",
        "outputId": "d1c38a1d-eefd-4763-ae17-6eed437902c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7b8ed9210484eaea7768523e0420bfc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ev in evaluate_json:\n",
        "  try:\n",
        "    ev['gpt2_output'] = ev['gpt2_output'].split('[OUTPUT]')[1]\n",
        "  except:\n",
        "    print(ev['gpt2_output'])\n",
        "    ev['gpt2_output'] = ''\n"
      ],
      "metadata": {
        "id": "ykQsnbE0Dov3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('./drive/My Drive/gpt2_results_for_eval_345m.jsonl', mode='w') as writer:\n",
        "    writer.write_all(evaluate_json)"
      ],
      "metadata": {
        "id": "2Fl6x3eoyPx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### evaluating ROUGE, BLEU"
      ],
      "metadata": {
        "id": "opozjeu7XWb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with jsonlines.open('./drive/My Drive/gpt2_results_for_eval_345m.jsonl', 'r') as jsonl_f:\n",
        "  evaluate_json = [obj for obj in jsonl_f]"
      ],
      "metadata": {
        "id": "Y3lMXms14SDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [j['gpt2_output'] for j in evaluate_json]\n",
        "references = [j['gold_output'] for j in evaluate_json]"
      ],
      "metadata": {
        "id": "M8EVCFgX3KP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load('rouge')\n",
        "results = rouge.compute(predictions=predictions,\n",
        "                        references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "id": "I4ZaHtqp3Fn2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ca51be-807f-4146-a825-566bba8acdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': 0.5406130836251282, 'rouge2': 0.2252333569469534, 'rougeL': 0.3432698156894707, 'rougeLsum': 0.46947325728397044}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [j['gpt2_output'] for j in evaluate_json]\n",
        "references = [[j['gold_output']] for j in evaluate_json]"
      ],
      "metadata": {
        "id": "TDuV1IjL4zJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "results = bleu.compute(predictions=predictions, references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za1DC7IM42Bf",
        "outputId": "7ca2537d-564a-42df-9f2a-b47ebb2f953c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 0.28974112270365965, 'precisions': [0.6100256387587304, 0.3600035520824083, 0.2261172063152261, 0.1419227667771705], 'brevity_penalty': 1.0, 'length_ratio': 1.0018600531443755, 'translation_length': 11311, 'reference_length': 11290}\n"
          ]
        }
      ]
    }
  ]
}